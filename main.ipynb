{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Novas Tecnologias em Banco de Dados</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dra. Sahudy Montenegro González</center></font>\n",
    "\n",
    "## <center>Projeto Prático - CONAB COTAÇÕES</center>\n",
    "\n",
    "**GRUPO 03**\n",
    "\n",
    "**Nome**: Mateus Tsuyoshi Matsuo Hashimoto e Pedro Gonçalves Correia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Web Scraping\n",
    "\n",
    "Nesta seção, será realizada a implementação do código referente ao web scraping do site da Companhia Nacional de Abastecimento (CONAB) a fim de extrair os dados a respeito das cotações dos insumos agropecuários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o site possui um captcha de imagem para acessar as tabelas contendo os dados das consultas, o que impossibilitou o web scraping por meio do WebDriver. Porém, a partir de algumas análises, o grupo descobriu uma forma de extrair os dados do site. Essa maneira consiste em utilizar uma url base e, a partir dela, gerar as urls para todas as consultas e, assim, conseguir extrair todos os dados do site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizar uma consulta manualmente, o grupo verificou que o link da página possuía o seguinte formato: https://consultaweb.conab.gov.br/consultas/consultaInsumo.do?d-6983528-p=1&uf=&anoFinal=2024&ano=2020&method=acaoListarConsulta&idSubGrupo=28&btnConsultar=Consultar&jcaptcha=WBLDS&idGrupo=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo:\n",
    "* <b>\"https://consultaweb.conab.gov.br/consultas/consultaInsumo.do\"</b>: a url base;\n",
    "* <b>\"p=1\"</b>: a paginação da tabela;\n",
    "* <b>\"uf=\"</b>: a UF selecionada para a consulta;\n",
    "* <b>\"anoFinal=2024\"</b>: o ano final do intervalo de tempo da consulta;\n",
    "* <b>\"ano=2020\"</b>: o ano inicial do intervalo de tempo da consulta;\n",
    "* <b>\"method=acaoListarConsulta\"</b>: o método do sistema para listar os dados da consulta;\n",
    "* <b>\"idSubGrupo=28\"</b>: o id do SubGrupo selecionado para a consulta;\n",
    "* <b>\"btnConsultar=Consultar\"</b>: o botão de confirmar a consulta;\n",
    "* <b>\"jcaptcha=WBLDS\"</b>: o captcha utilizado para realizar a consulta;\n",
    "* <b>\"idGrupo=9\"</b>: o id do Grupo selecionado para a consulta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nisso, o grupo alterou o link manualmente para verificar se seria possível realizar uma consulta diferente com o mesmo captcha, a fim de tentar solucionar essa questão impeditiva até então. Felizmente, foi possível concluir essa consulta graças à uma falha de segurança no sistema do site. A partir disso, a equipe realizou o código do web scraping a seguir.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos realizar a importação das bibliotecas que serão utilizadas no projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Realiza requisições HTTP para acessar páginas web\n",
    "from bs4 import BeautifulSoup  # Faz parsing do HTML e extração de informações de páginas web\n",
    "import pandas as pd  # Manipula e analisa dados, especialmente em dataframes\n",
    "import time  # Permite controlar o tempo, inserindo delays entre requisições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos estabelecer a url base e os parâmetros fixos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url base\n",
    "url = \"https://consultaweb.conab.gov.br/consultas/consultaInsumo.do\"\n",
    "\n",
    "# Parâmetros fixos\n",
    "ANO_INICIAL = 2020\n",
    "ANO_FINAL = 2024\n",
    "JCAPTCHA = \"WBLDS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, criaremos 3 dicionários fundamentais para realizar o web scraping desse site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro dicionário serve para associar os grupos com os seus subgrupos por meio do id, para poder realizar todas as consultas possíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_subgrupos = {\n",
    "    9: [28, 29, 30, 31, 33, 35],\n",
    "    27: [32, 70, 71],\n",
    "    31: [127, 128, 129],\n",
    "    57: [137, 319, 339],\n",
    "    39: [139, 140, 322]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segundo e o terceiro dicionário servem para mapear os ids dos grupos para os seus nomes e os ids dos subgrupos para os seus nomes, respectivamente. Esses dicionários têm como objetivo armazenar os nomes dos grupos e subgrupos, uma vez que as tabelas resultantes das consultas só possuem os nomes dos produtos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para mapear os IDs para os nomes dos grupos\n",
    "grupos_nomes = {\n",
    "    9: \"Agrotóxico\",\n",
    "    27: \"Fertilizante\",\n",
    "    31: \"Implemento\",\n",
    "    57: \"Máquinas/Motores\",\n",
    "    39: \"Material Propagativo\"\n",
    "}\n",
    "\n",
    "# Dicionário para mapear os IDs para os nomes dos subgrupos\n",
    "subgrupos_nomes = {\n",
    "    28: \"Acaricida\",\n",
    "    29: \"Espalhante/Adjuvante\",\n",
    "    30: \"Fungicida\",\n",
    "    31: \"Herbicida\",\n",
    "    33: \"Inseticida\",\n",
    "    35: \"Estimulante/Regulador de Crescimento\",\n",
    "    32: \"Inoculante\",\n",
    "    70: \"Orgânico\",\n",
    "    71: \"Químico\",\n",
    "    127: \"Colheitadeira\",\n",
    "    128: \"Manual\",\n",
    "    129: \"Mecânico\",\n",
    "    137: \"Máquina Agrícola\",\n",
    "    319: \"Conjunto\",\n",
    "    339: \"Máquina\",\n",
    "    139: \"Mudas\",\n",
    "    140: \"Sementes\",\n",
    "    322: \"Maniva\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos criar duas listas, uma para armazenar os dados coletados e outra para pegar os cabeçalhos da tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] # Lista para armazenar os dados coletados\n",
    "headers = [] # Lista para armazenar os titulos das colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, iremos extrair todos os dados das tabelas geradas a partir das consultas acessadas por meio da construção das urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para cada combinação de grupo e subgrupo\n",
    "for id_grupo, subgrupos in grupos_subgrupos.items():\n",
    "    for id_subgrupo in subgrupos:\n",
    "        pagina = 1  # Começa na primeira página\n",
    "        \n",
    "        while True:\n",
    "            # Parâmetros da requisição\n",
    "            parametros = {\n",
    "                \"d-6983528-p\": pagina,\n",
    "                \"uf\": \"\",\n",
    "                \"anoFinal\": ANO_FINAL,\n",
    "                \"ano\": ANO_INICIAL,\n",
    "                \"method\": \"acaoListarConsulta\",\n",
    "                \"idSubGrupo\": id_subgrupo,\n",
    "                \"btnConsultar\": \"Consultar\",\n",
    "                \"jcaptcha\": JCAPTCHA,\n",
    "                \"idGrupo\": id_grupo    \n",
    "            }\n",
    "            \n",
    "            resposta = requests.get(url, params=parametros) # Fazendo a requisição\n",
    "            \n",
    "            print(resposta.url)\n",
    "            \n",
    "            # Verifica se a requisição foi bem-sucedida\n",
    "            if resposta.status_code != 200:\n",
    "                print(f\"Erro ao acessar {resposta.url}: {resposta.status_code}\")\n",
    "                break\n",
    "            \n",
    "            soup = BeautifulSoup(resposta.text, 'html.parser') # Parseando a página\n",
    "            table = soup.find('table', {'id': 'tabelaInsumo'}) # Encontra a tabela\n",
    "            \n",
    "            # Se não há dados, paramos a iteração\n",
    "            if table is None:\n",
    "                break\n",
    "            \n",
    "            # Na primeira iteração, extrai os headers\n",
    "            if pagina == 1 and not data:\n",
    "                for i in table.find_all('th'):\n",
    "                    title = i.text.strip()\n",
    "                    headers.append(title)\n",
    "                headers.extend(['Grupo', 'Subgrupo']) # Acrescenta os headers de grupo e subgrupo\n",
    "            \n",
    "            page_data = [] # Lista para armazenar os dados da página\n",
    "            \n",
    "            # Extraindo dados da tabela\n",
    "            for row in table.find_all('tr')[1:]:\n",
    "                cols = row.find_all('td')\n",
    "                row_data = [col.text.replace('\\n', '').strip() for col in cols]\n",
    "                grupo_valor = grupos_nomes.get(id_grupo) # Pega o valor(nome) do grupo pelo id_grupo\n",
    "                subgrupo_valor = subgrupos_nomes.get(id_subgrupo) # Pega o valor(nome) do subgrupo pelo id_subgrupo\n",
    "                row_data.extend([grupo_valor, subgrupo_valor]) # Adiciona o valor(nome) do grupo e subgrupo\n",
    "                page_data.append(row_data)\n",
    "            \n",
    "            data.extend(page_data) # Armazena os dados coletados\n",
    "            \n",
    "            print(f\"Grupo {id_grupo} | Subgrupo {id_subgrupo} | Página {pagina} | {len(page_data)} registros coletados.\")\n",
    "            \n",
    "            pagina += 1 # Próxima página\n",
    "            \n",
    "            time.sleep(1) # Adiciona um pequeno delay para evitar sobrecarga no servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a extração de todos os dados do site, vamos converte-los para um dataframe e salvá-los em um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('insumos_agropecuarios.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Limpeza e Pré-processamento dos dados\n",
    "\n",
    "Nesta seção, vamos realizar a preparação dos dados extraídos pelo web scraping a fim de assegurar a qualidade deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, iremos analisar algumas características desse conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, vamos transformar algumas variáveis categóricas em numéricas com o intuito de analisar os valores estatísticos delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Ano', 'Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'] # Lista de colunas a serem convertidas para numéricas\n",
    "\n",
    "for column in cat:\n",
    "    df[column] = pd.to_numeric(df[column].astype(str).str.replace(',', ''), errors='coerce') # Remover o separador de milhar e converter para numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, criaremos uma nova variável para armazenar a região do país de cada cotação a partir de sua UF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, será necessário criar um dicionário para o mapeamento de UF para região e depois, utilizar o método map( ) para criar a nova variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para mapear as regiões a partir das UFs\n",
    "regioes = {\n",
    "    'Norte': ['AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO'],\n",
    "    'Nordeste': ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE'],\n",
    "    'Centro-Oeste': ['GO', 'MT', 'MS', 'DF'],\n",
    "    'Sudeste': ['ES', 'MG', 'RJ', 'SP'],\n",
    "    'Sul': ['PR', 'RS', 'SC']\n",
    "}\n",
    "\n",
    "uf_regiao = {uf: regiao for regiao, ufs in regioes.items() for uf in ufs} # Inverte o dicionário de regiões: para cada UF, associa-se sua região\n",
    "df['Regiao'] = df['UF'].map(uf_regiao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos reorganizar as colunas do dataframe para uma melhor visualização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['Grupo', 'Subgrupo', 'Produto', 'Unidade', 'Regiao', 'UF', 'Ano', 'Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'] # Lista com a nova ordem das colunas\n",
    "\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins analíticos dos dados coletados, não iremos realizar o tratamento de valores nulos, pois vamos analisar se teve ou não produção de um determinado produto em um determinado mês/ano. Portanto, manter esses valores é de extrema importância para o objetivo do negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('insumos_agropecuarios_tratados.csv', index=False) # Salva o dataframe tratado em um arquivo CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Integração com o banco de dados do PostgreSQL\n",
    "\n",
    "Nesta seção, iremos conectar ao banco de dados do PostgreSQL para armazenar os dados coletados e pré-processados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos importar a biblioteca SQLAlchemy para fazer essa conexão com o banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos estabelecer os dados de conexão com o banco local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = '<seu_usuario>' \n",
    "password = '<sua_senha>'\n",
    "host = '<host_da_conexao>'         \n",
    "port = '<porta_da_conexao>'\n",
    "database = '<nome_do_banco>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criaremos uma url de conexão, que é utilizada pela engine para estabelecer a conexão com o PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}' # Cria a URL de conexão\n",
    "\n",
    "engine = create_engine(connection_string) # Cria o engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após estabelecer a conexão e criar as tabelas de dimensão e de fato no Data Warehouse por meio do script 'DDL.sql', iremos realizar o povoamento delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Povoamento do Data Warehouse - Dimensões e Tabela Fato\n",
    "\n",
    "Nesta seção, será realizado o povoamento das tabelas do DW, diretamente do DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos popular a Dimensão Local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona as colunas 'UF' e 'Regiao' do dataframe, remove as duplicadas e renomeia as colunas para igualar aos da tabela no PostgreSQL\n",
    "df_local = df[['UF', 'Regiao']].drop_duplicates().rename(columns={'UF': 'estado', 'Regiao': 'regiao'})\n",
    "\n",
    "# Insere o dataframe na tabela 'dim_local' do banco de dados\n",
    "df_local.to_sql('dim_local', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Dimensão Local carregada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos popular a Dimensão Produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona as colunas 'Produto', 'Subgrupo', 'Grupo' e 'Unidade' do dataframe, remove as duplicadas e renomeia as colunas para igualar aos da tabela no PostgreSQL\n",
    "df_produto = df[['Produto', 'Subgrupo', 'Grupo', 'Unidade']].drop_duplicates().rename(columns={'Produto': 'nome_produto', 'Subgrupo': 'subgrupo', 'Grupo': 'grupo', 'Unidade': 'unidade_medida'})\n",
    "\n",
    "# Insere o dataframe na tabela 'dim_produto' do banco de dados\n",
    "df_produto.to_sql('dim_produto', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Dimensão Produto carregada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos popular a Dimensão Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário que mapeia o número do mês para seu nome por extenso\n",
    "month_names = {\n",
    "    1: 'Janeiro', \n",
    "    2: 'Fevereiro', \n",
    "    3: 'Março', \n",
    "    4: 'Abril', \n",
    "    5: 'Maio', \n",
    "    6: 'Junho',\n",
    "    7: 'Julho', \n",
    "    8: 'Agosto', \n",
    "    9: 'Setembro', \n",
    "    10: 'Outubro', \n",
    "    11: 'Novembro', \n",
    "    12: 'Dezembro'\n",
    "}\n",
    "\n",
    "anos = sorted(df['Ano'].unique()) # Ordena os anos únicos presentes na coluna 'ano'\n",
    "dim_data_rows = [] # Lista para armazenar os registros da dimensão de data\n",
    "\n",
    "# Para cada ano e para cada mês (1 a 12), gera os registros com o trimestre correspondente\n",
    "for ano in anos:\n",
    "    for mes in range(1, 13):\n",
    "        # Define o trimestre com base no mês:\n",
    "        if mes in (1, 2, 3):\n",
    "            trimestre = 1\n",
    "        elif mes in (4, 5, 6):\n",
    "            trimestre = 2\n",
    "        elif mes in (7, 8, 9):\n",
    "            trimestre = 3\n",
    "        else:\n",
    "            trimestre = 4\n",
    "        \n",
    "        # Cria um registro com mês, ano, nome do mês e trimestre\n",
    "        dim_data_rows.append({\n",
    "            'mes': mes,\n",
    "            'ano': ano,\n",
    "            'mes_por_extenso': month_names[mes],\n",
    "            'trimestre': trimestre\n",
    "        })\n",
    "\n",
    "df_data = pd.DataFrame(dim_data_rows) # Converte a lista de registros em um DataFrame\n",
    "df_data.to_sql('dim_data', engine, if_exists='append', index=False) # Insere o dataframe na tabela 'dimensao_data' do banco de dados\n",
    "\n",
    "print(\"Dimensão Data carregada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos popular a Tabela Fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega as colunas dos meses do DataFrame\n",
    "month_cols = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
    "\n",
    "# Converte o DataFrame de formato wide (cada coluna representa um mês) para long (cada linha representa uma observação mensal), mantendo as colunas de identificação\n",
    "df_fact = pd.melt(df,\n",
    "                  id_vars=['UF', 'Regiao', 'Produto', 'Subgrupo', 'Grupo', 'Unidade', 'Ano'], # mantém as colunas de identificação\n",
    "                  value_vars=month_cols, # transforma as colunas dos meses especificados\n",
    "                  var_name='mes_nome', # coluna que contém os nomes dos meses\n",
    "                  value_name='preco') # coluna que contém os preços\n",
    "\n",
    "# Mapeia as abreviações dos meses para seus números correspondentes\n",
    "month_mapping = {\n",
    "    'Jan': 1, \n",
    "    'Fev': 2, \n",
    "    'Mar': 3, \n",
    "    'Abr': 4, \n",
    "    'Mai': 5, \n",
    "    'Jun': 6,\n",
    "    'Jul': 7, \n",
    "    'Ago': 8, \n",
    "    'Set': 9, \n",
    "    'Out': 10, \n",
    "    'Nov': 11, \n",
    "    'Dez': 12\n",
    "}\n",
    "\n",
    "# Cria uma nova coluna 'Mes' com o número do mês correspondente\n",
    "df_fact['Mes'] = df_fact['mes_nome'].map(month_mapping)\n",
    "\n",
    "# Carrega as dimensões já populadas no banco de dados\n",
    "df_local_dw = pd.read_sql(\"SELECT * FROM dim_local\", engine)\n",
    "df_produto_dw = pd.read_sql(\"SELECT * FROM dim_produto\", engine)\n",
    "df_data_dw = pd.read_sql(\"SELECT * FROM dim_data\", engine)\n",
    "\n",
    "# Realiza joins para agregar as chaves estrangeiras\n",
    "df_fact = df_fact.merge(df_local_dw, left_on=['UF', 'Regiao'], right_on=['estado', 'regiao'], how='left')\n",
    "df_fact = df_fact.merge(df_produto_dw, left_on=['Produto', 'Subgrupo', 'Grupo', 'Unidade'], right_on=['nome_produto', 'subgrupo', 'grupo', 'unidade_medida'], how='left')\n",
    "df_fact = df_fact.merge(df_data_dw, left_on=['Mes', 'Ano'], right_on=['mes', 'ano'], how='left')\n",
    "\n",
    "# Remove preços iguais a zero antes da inserção \n",
    "df_fact = df_fact[(df_fact['preco'] > 0)]\n",
    "\n",
    "# Seleciona apenas as colunas necessárias para a tabela fato\n",
    "df_fact_final = df_fact[['id_local', 'id_data', 'id_produto', 'preco']]\n",
    "\n",
    "# Insere o dataframe na tabela 'fato_cotacao' do banco de dados\n",
    "df_fact_final.to_sql('fato_cotacao', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Tabela Fato carregada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise dos resultados das consultas\n",
    "\n",
    "Nesta seção, será realizada a análise dos resultados das consultas realizadas no PostgreSQL através do arquivo *consultas.sql*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como iremos plotar gráficos para auxiliar na análise dos resultados, vamos importar as bibliotecas *matpltolib* e *seaborn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando os resultados da consulta 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM mv_preco_medio_tempo;\" # Recupera os resultados da materialized view\n",
    "\n",
    "df_consulta1 = pd.read_sql_query(query, engine) # Executa a consulta e armazena o resultado em um DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar a análise da consulta 1, iremos plotar um gráfico de linha que permite visualizar tendências e sazonalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma coluna 'date' combinando ano e mês\n",
    "df_consulta1['date'] = pd.to_datetime(df_consulta1['ano'].astype(str) + '-' + df_consulta1['mes'].astype(str) + '-01')\n",
    "df_consulta1 = df_consulta1.sort_values('date')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x='date', y='preco_medio', data=df_consulta1, marker='o')\n",
    "plt.title('Evolução do Preço Médio ao Longo do Tempo')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Médio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões a partir do gráfico: É possível observar que nos últimos 3 anos, no início desses anos teve um pico no preço do produto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando os resultados da consulta 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM mv_preco_medio_regiao;\" # Recupera os resultados da materialized view\n",
    "\n",
    "df_consulta2 = pd.read_sql_query(query, engine) # Executa a consulta e armazena o resultado em um DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar a análise da consulta 2, iremos plotar um gráfico de barras que facilita fazer a comparação entre as regiões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='regiao', y='preco_medio', data=df_consulta2, palette='viridis')\n",
    "plt.title('Preço Médio por Região')\n",
    "plt.xlabel('Região')\n",
    "plt.ylabel('Preço Médio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando os resultados da consulta 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera a consulta realizada por região\n",
    "query = \"SELECT * FROM mv_produtos_regiao;\" # Recupera os resultados da materialized view\n",
    "df_consulta3r = pd.read_sql_query(query, engine) # Executa a consulta e armazena o resultado em um DataFrame\n",
    "\n",
    "# Recupera a consulta realizada por estado\n",
    "query = \"SELECT * FROM mv_produtos_estado;\" # Recupera os resultados da materialized view\n",
    "df_consulta3e = pd.read_sql_query(query, engine) # Executa a consulta e armazena o resultado em um DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar a análise da consulta 3, iremos plotar um gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_grupo = df_consulta3r.groupby('grupo').size().reset_index(name='count') # Contabiliza a quantidade de produtos por grupo\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='grupo', y='count', data=df_count_grupo, palette='magma')\n",
    "plt.title('Quantidade de Produtos por Grupo na Região')\n",
    "plt.xlabel('Grupo')\n",
    "plt.ylabel('Quantidade de Produtos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_count_subgrupo = df_consulta3r.groupby('subgrupo').size().reset_index(name='count') # Contabiliza a quantidade de produtos por subgrupo\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='subgrupo', y='count', data=df_count_subgrupo, palette='magma')\n",
    "plt.title('Quantidade de Produtos por Subgrupo na Região')\n",
    "plt.xlabel('Subgrupo')\n",
    "plt.ylabel('Quantidade de Produtos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_grupo = df_consulta3e.groupby('grupo').size().reset_index(name='count') # Contabiliza a quantidade de produtos por grupo\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='grupo', y='count', data=df_count_grupo, palette='magma')\n",
    "plt.title('Quantidade de Produtos por Grupo no Estado')\n",
    "plt.xlabel('Grupo')\n",
    "plt.ylabel('Quantidade de Produtos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_count_subgrupo = df_consulta3e.groupby('subgrupo').size().reset_index(name='count') # Contabiliza a quantidade de produtos por subgrupo\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='subgrupo', y='count', data=df_count_subgrupo, palette='magma')\n",
    "plt.title('Quantidade de Produtos por Subgrupo no Estado')\n",
    "plt.xlabel('Subgrupo')\n",
    "plt.ylabel('Quantidade de Produtos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando os resultados da consulta 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM mv_preco_tipo;\" # Recupera os resultados da materialized view\n",
    "\n",
    "df_consulta4 = pd.read_sql_query(query, engine) # Executa a consulta e armazena o resultado em um DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a análise da consulta 4, vamos plotar um gráfico de barras com barras de erro (indicando o desvio padrão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando um gráfico de barras com erro para cada subgrupo (agrupados por grupo)\n",
    "# Para facilitar a visualização, vamos criar uma coluna combinada para identificar o subgrupo\n",
    "df_consulta4['tipo'] = df_consulta4['grupo'] + ' - ' + df_consulta4['subgrupo']\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "# Cria uma posição para cada tipo\n",
    "x = range(len(df_consulta4))\n",
    "plt.bar(x, df_consulta4['preco_medio'], yerr=df_consulta4['preco_desvio_padrao'], capsize=5, color='skyblue')\n",
    "plt.xticks(x, df_consulta4['tipo'], rotation=45, ha='right')\n",
    "plt.title('Variação dos Preços por Tipo de Produto')\n",
    "plt.xlabel('Tipo (Grupo - Subgrupo)')\n",
    "plt.ylabel('Preço Médio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
