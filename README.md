# ğŸŒ¾ğŸšœ Data Warehouse de Insumos AgropecuÃ¡rios ğŸŒ±ğŸŒ¿

Este repositÃ³rio contÃ©m o projeto final da disciplina de Novas Tecnologias em Banco de Dados, realizado por Mateus Matsuo (@mateusmatsuo) e Pedro Correia (@PedroGCorreia), em que foi construÃ­do um data warehouse focado em insumos agrÃ­colas. Durante o desenvolvimento do trabalho, a equipe realizou as seguintes tarefas:

* Modelagem do DW e estruturaÃ§Ã£o das consultas;
* Webscraping do site da [Conab](https://consultaweb.conab.gov.br/consultas/consultaInsumo.do?method=acaoCarregarConsulta);
* ETL com os dados obtidos;
* RealizaÃ§Ã£o das consultas e anÃ¡lise dos seus resultados;

## Estrutura do projeto

* ğŸ—„ï¸ dataset/: contÃ©m dois arquivos .csv gerados ao longo da implementaÃ§Ã£o;
    * insumos_agropecuarios.csv â€“ Dados extraÃ­dos diretamente via web scraping;
    * insumos_agropecuarios_tratados.csv â€“ Dados resultantes apÃ³s o tratamento e limpeza.
* ğŸ“ scripts/: contÃ©m os scripts em SQL utilizados para criar e utilizar o Data Warehouse;
    * DDL.sql - Script para criaÃ§Ã£o de tabelas do DW;
    * consultas.sql â€“ Script com as consultas realizadas.
* ğŸ“ main.ipynb - Noteook que demostra os processos de webscraping, ETL dos dados e anÃ¡lise das consultas;
* ğŸ’¾ dw_backup.sql â€“ Backup completo do data warehouse;
* âš™ï¸ requirements.txt â€“ Lista de dependÃªncias necessÃ¡rias para execuÃ§Ã£o do projeto;
* ğŸ“š README.md - documentaÃ§Ã£o do projeto.

## Etapas do projeto

1. Modelagem e estruturaÃ§Ã£o das consultas:
* Neste momento, foi projetado o seguinte modelo para implementaÃ§Ã£o nas fases posteriores.

![Modelo Data Warehouse](./figs/Modelo_DW.jpg)

* AlÃ©m disso, foram pensadas as quatro consultas abaixo para serem rodadas no DW.

    * AnÃ¡lise dos preÃ§os ao longo de determinado perÃ­odo de tempo;
    * ComparaÃ§Ã£o dos preÃ§os do produto por regiÃ£o;
    * IdentificaÃ§Ã£o da produÃ§Ã£o em um determinado local;
    * VariaÃ§Ãµes dos preÃ§os de acordo com o tipo de produto.

2. Webscraping dos dados: extraÃ§Ã£o de dados da pÃ¡gina web utilizando as tÃ©cnicas demonstradas no `main.ipynb`.

3. ETL dos dados: apÃ³s a extraÃ§Ã£o na fase 2, os dados foram tratados aplicando a transformaÃ§Ã£o de tipos de atributos, criaÃ§Ã£o da coluna regiÃ£o a partir do estado, elaboraÃ§Ã£o de mapeamento entre atributos (trimestre e mÃªs) e definiÃ§Ã£o de estratÃ©gia para o tratamento dos valores nulos e, entÃ£o, houve a carga do DW com o resultado das operaÃ§Ãµes;

4. RealizaÃ§Ã£o das consultas e anÃ¡lise dos seus resultados: as consultas foram executadas dentro do postgreSQL por meio do arquivo `consultas.sql` e os resultados dessas queries foram analisados por meio do notebook.

## âš™ï¸ Como executar o projeto
1. Clone o repositÃ³rio:
```
git clone https://github.com/PedroGCorreia/Data-Warehouse.git
cd Data-Warehouse
```

2. Configure o ambiente:
* Certifique-se de ter o Python instalado na sua mÃ¡quina;
* Instale as dependÃªncias necessÃ¡rias com o seguinte comando.
```
pip install -r requirements.txt
```

3. Abra o arquivo `main.ipynb` e execute as cÃ©lulas atÃ© a finalizaÃ§Ã£o da etapa ETL;

4. Execute o script `DDL.sql` (localizado na pasta de scripts) para criar as tabelas do DW e retorne para o `main.ipynb` para realizar a integraÃ§Ã£o com o postgreSQL e realizar a carga do banco com os dados tratados;

* OBS.: lembre-se de alterar a cÃ©lula de conexÃ£o com o postgreSQL para preecher com os dados de usuÃ¡rio, senha, host, porta da conexÃ£o e nome do DW corretamente.

5. Realize as consultas SQL por meio do arquivo `consultas.sql` dentro do postgreSQL para verificar os seus resultados;

6. Por fim, retorne para o `main.ipynb` e execute a Ãºltima seÃ§Ã£o com a anÃ¡lise das consultas executadas.

* OBS.: os arquivos da pasta dataset e o backup do banco podem ser utilizados para poupar passos desse processo, contudo sugerimos que a execuÃ§Ã£o ocorra dessa forma para melhor compreensÃ£o do projeto como um todo.

## ConsideraÃ§Ãµes finais

Este projeto demonstra uma aplicaÃ§Ã£o prÃ¡tica acerca de banco de dados, desde a modelagem atÃ© a anÃ¡lise dos dados em um ambiente de Data Warehouse, alÃ©m de demonstrar o conhecimento em diferentes linguagens e ferramentas como Python, SQL e PostgreSQL.